{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "\n",
    "Word embedding is any of a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec \n",
    "\n",
    "\n",
    "### Statistical Language Model\n",
    "A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability. to the whole sequence. The language model provides context to distinguish between words and phrases that sound similar.\n",
    "\n",
    "\n",
    "### CBOW\n",
    "Given context, setup a neural net to predict next word\n",
    "\n",
    "### SkipGram \n",
    "Given a word in the text sequence, setup a neural net to predict the sequence.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/word2vec.jpg\"> \n",
    "\n",
    "\n",
    "Context size is fixed (hyperparameter) and the input to the neural net is the k words of the context in 1-hot representation.\n",
    "\n",
    "So if we have 1000 words in the vocab and context 4, the input in CBOW will be 4 stacked 1000 dimensional 1-hot vectors (one vector for each word in the context) and the target vector a 1000 dimensional target vector of the probabilities of the next word.\n",
    "\n",
    "The hidden layer would be of dimensionality D (again hyperparameter). The byproduct of the training then are two matrices, the input-hidden layer weights and the hidden-output layer weights.\n",
    "\n",
    "Both matrices have dimensions $Dx|V|$, where D the hidden layer dimension and $|V|$ the size of the vocabulary.\n",
    "\n",
    "\n",
    "Similarily, the configuration of the skip-gram architecture is similar:\n",
    "\n",
    "Input vector 1-hot encoding of the input word, output vectors k softmax vectors of dimension $|V|$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "import numpy as np\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "    \n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "            \n",
    "    def __iter__(self):\n",
    "        for line in self.lines:\n",
    "            \n",
    "            text = line.lower()\n",
    "            \n",
    "            yield gensim.utils.simple_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(\"./data/amazon_reviews.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bought', 'this', 'album', 'because', 'loved', 'the', 'title', 'song', 'it', 'such', 'great', 'song', 'how', 'bad', 'can', 'the', 'rest', 'of', 'the', 'album', 'be', 'right', 'well', 'the', 'rest', 'of', 'the', 'songs', 'are', 'just', 'filler', 'and', 'are', 'worth', 'the', 'money', 'paid', 'for', 'this', 'it', 'either', 'shameless', 'bubblegum', 'or', 'depressing', 'tripe', 'kenny', 'chesney', 'is', 'popular', 'artist', 'and', 'as', 'result', 'he', 'is', 'in', 'the', 'cookie', 'cutter', 'category', 'of', 'the', 'nashville', 'music', 'scene', 'he', 'gotta', 'pump', 'out', 'the', 'albums', 'so', 'the', 'record', 'company', 'can', 'keep', 'lining', 'their', 'pockets', 'while', 'the', 'suckers', 'out', 'there', 'keep', 'buying', 'this', 'garbage', 'to', 'perpetuate', 'more', 'garbage', 'coming', 'out', 'of', 'that', 'town', 'll', 'get', 'down', 'off', 'my', 'soapbox', 'now', 'but', 'country', 'music', 'really', 'needs', 'to', 'get', 'back', 'to', 'it', 'roots', 'and', 'stop', 'this', 'pop', 'nonsense', 'what', 'country', 'music', 'really', 'is', 'and', 'what', 'it', 'is', 'considered', 'to', 'be', 'by', 'mainstream', 'are', 'two', 'different', 'things']\n"
     ]
    }
   ],
   "source": [
    "sentences = MyCorpus(data)\n",
    "for s in sentences:\n",
    "    print(s)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 01:06:51,120 : INFO : collecting all words and their counts\n",
      "2020-12-03 01:06:51,122 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-12-03 01:06:53,253 : INFO : PROGRESS: at sentence #10000, processed 1242775 words, keeping 41603 word types\n",
      "2020-12-03 01:06:53,661 : INFO : collected 45128 word types from a corpus of 1480752 raw words and 11914 sentences\n",
      "2020-12-03 01:06:53,662 : INFO : Loading a fresh vocabulary\n",
      "2020-12-03 01:06:53,711 : INFO : effective_min_count=5 retains 13926 unique words (30% of original 45128, drops 31202)\n",
      "2020-12-03 01:06:53,712 : INFO : effective_min_count=5 leaves 1429573 word corpus (96% of original 1480752, drops 51179)\n",
      "2020-12-03 01:06:53,762 : INFO : deleting the raw counts dictionary of 45128 items\n",
      "2020-12-03 01:06:53,764 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2020-12-03 01:06:53,765 : INFO : downsampling leaves estimated 1091047 word corpus (76.3% of prior 1429573)\n",
      "2020-12-03 01:06:53,803 : INFO : estimated required memory for 13926 words and 200 dimensions: 29244600 bytes\n",
      "2020-12-03 01:06:53,804 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec( min_count=5, workers=5, size=200) \n",
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 01:07:31,503 : INFO : training model with 5 workers on 13926 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-12-03 01:07:32,553 : INFO : EPOCH 1 - PROGRESS: at 25.37% examples, 272751 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:33,597 : INFO : EPOCH 1 - PROGRESS: at 59.64% examples, 310007 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:34,637 : INFO : EPOCH 1 - PROGRESS: at 92.82% examples, 323266 words/s, in_qsize 10, out_qsize 0\n",
      "2020-12-03 01:07:34,717 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-03 01:07:34,718 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-03 01:07:34,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-03 01:07:34,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-03 01:07:34,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-03 01:07:34,730 : INFO : EPOCH - 1 : training on 1480752 raw words (1090851 effective words) took 3.2s, 339625 effective words/s\n",
      "2020-12-03 01:07:35,819 : INFO : EPOCH 2 - PROGRESS: at 26.03% examples, 267937 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:36,856 : INFO : EPOCH 2 - PROGRESS: at 60.86% examples, 311205 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:37,840 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-03 01:07:37,848 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-03 01:07:37,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-03 01:07:37,852 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-03 01:07:37,857 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 349818 words/s, in_qsize 0, out_qsize 1\n",
      "2020-12-03 01:07:37,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-03 01:07:37,859 : INFO : EPOCH - 2 : training on 1480752 raw words (1090939 effective words) took 3.1s, 349551 effective words/s\n",
      "2020-12-03 01:07:38,915 : INFO : EPOCH 3 - PROGRESS: at 25.37% examples, 270765 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:39,992 : INFO : EPOCH 3 - PROGRESS: at 62.04% examples, 317880 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:40,912 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-03 01:07:40,918 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-03 01:07:40,922 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-03 01:07:40,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-03 01:07:40,930 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-03 01:07:40,930 : INFO : EPOCH - 3 : training on 1480752 raw words (1090944 effective words) took 3.1s, 356718 effective words/s\n",
      "2020-12-03 01:07:41,948 : INFO : EPOCH 4 - PROGRESS: at 32.90% examples, 352093 words/s, in_qsize 0, out_qsize 0\n",
      "2020-12-03 01:07:42,961 : INFO : EPOCH 4 - PROGRESS: at 60.37% examples, 322390 words/s, in_qsize 9, out_qsize 0\n",
      "2020-12-03 01:07:43,950 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-03 01:07:43,953 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-03 01:07:43,956 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-03 01:07:43,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-03 01:07:43,964 : INFO : EPOCH 4 - PROGRESS: at 100.00% examples, 360715 words/s, in_qsize 0, out_qsize 1\n",
      "2020-12-03 01:07:43,964 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-03 01:07:43,965 : INFO : EPOCH - 4 : training on 1480752 raw words (1091214 effective words) took 3.0s, 360577 effective words/s\n",
      "2020-12-03 01:07:44,982 : INFO : EPOCH 5 - PROGRESS: at 26.03% examples, 289278 words/s, in_qsize 7, out_qsize 0\n",
      "2020-12-03 01:07:45,999 : INFO : EPOCH 5 - PROGRESS: at 58.46% examples, 312031 words/s, in_qsize 7, out_qsize 2\n",
      "2020-12-03 01:07:47,004 : INFO : EPOCH 5 - PROGRESS: at 91.41% examples, 328887 words/s, in_qsize 10, out_qsize 1\n",
      "2020-12-03 01:07:47,055 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-12-03 01:07:47,061 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-12-03 01:07:47,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-12-03 01:07:47,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-12-03 01:07:47,070 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-12-03 01:07:47,071 : INFO : EPOCH - 5 : training on 1480752 raw words (1091469 effective words) took 3.1s, 353124 effective words/s\n",
      "2020-12-03 01:07:47,072 : INFO : training on a 7403760 raw words (5455417 effective words) took 15.6s, 350419 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5455417, 7403760)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentences = MyCorpus(data)\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 01:08:11,966 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ridiculous', 0.8187541961669922),\n",
       " ('scary', 0.7904298901557922),\n",
       " ('terrible', 0.785262405872345),\n",
       " ('stupid', 0.7838867902755737),\n",
       " ('lame', 0.7792518138885498),\n",
       " ('plainly', 0.772826075553894),\n",
       " ('joke', 0.7724997997283936),\n",
       " ('plain', 0.771803081035614),\n",
       " ('kinda', 0.7712831497192383),\n",
       " ('absolutely', 0.7675280570983887)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lens', 0.891923189163208),\n",
       " ('bag', 0.8825212717056274),\n",
       " ('unit', 0.8497478365898132),\n",
       " ('camcorder', 0.8489190340042114),\n",
       " ('battery', 0.8283607959747314),\n",
       " ('tripod', 0.8274000883102417),\n",
       " ('case', 0.8206779956817627),\n",
       " ('canon', 0.8135760426521301),\n",
       " ('charger', 0.8048727512359619),\n",
       " ('razor', 0.7936983108520508)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('novel', 0.7962727546691895),\n",
       " ('author', 0.7322311997413635),\n",
       " ('movie', 0.7139641642570496),\n",
       " ('story', 0.6948456764221191),\n",
       " ('books', 0.6827583312988281),\n",
       " ('writing', 0.6768943071365356),\n",
       " ('read', 0.6709310412406921),\n",
       " ('film', 0.65472412109375),\n",
       " ('bible', 0.6295198202133179),\n",
       " ('review', 0.6107279062271118)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.9205185770988464),\n",
       " ('story', 0.8234798312187195),\n",
       " ('novel', 0.8226872682571411),\n",
       " ('plot', 0.7506477236747742),\n",
       " ('show', 0.7407904863357544),\n",
       " ('ending', 0.7253567576408386),\n",
       " ('book', 0.7139641046524048),\n",
       " ('album', 0.708283543586731),\n",
       " ('song', 0.7051331996917725),\n",
       " ('guy', 0.6938921809196472)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(10)\n",
    "\n",
    "kmeans.fit(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quiet upfront capture determine meeting\n",
      "\n",
      "\n",
      "chesney popular in while ll\n",
      "\n",
      "\n",
      "album money result category gotta\n",
      "\n",
      "\n",
      "bought such how bad shameless\n",
      "\n",
      "\n",
      "loved great rest be are\n",
      "\n",
      "\n",
      "kenny keep town my brilliant\n",
      "\n",
      "\n",
      "title it of just filler\n",
      "\n",
      "\n",
      "out mainstream cd many they\n",
      "\n",
      "\n",
      "can well either artist as\n",
      "\n",
      "\n",
      "this because the song right\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    ret = np.where( labels==i)[0]\n",
    "    \n",
    "    words = [vocab[ret[j]] for j in range( min(5, len(ret)) )]\n",
    "    print( \" \".join(words))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
