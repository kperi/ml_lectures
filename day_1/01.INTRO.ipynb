{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - An introduction\n",
    "\n",
    "\n",
    "## Structure of  the class  \n",
    "___\n",
    "\n",
    "### Part I: Machine Learning\n",
    "  - Basics & Theory\n",
    "    - What's this all about?\n",
    "    - Supervised, Unsupervised Learning\n",
    "    - Classification, Regression, Clustering\n",
    "  - Python Basics for Data Science / ML\n",
    "    - numpy, scipy\n",
    "    - scikit learn\n",
    "    - pytorch\n",
    "  - Hands-on examples\n",
    "    - Classification\n",
    "        * Churn prediction\n",
    "        * Digit classification\n",
    "    - Regression example\n",
    "        * Estimating House Prices\n",
    "    - Clustering\n",
    "        - kmeans document clustering\n",
    "\n",
    "\n",
    "  - What is Machine Learning anyway?\n",
    "  - Some examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "\n",
    "A (very informal) definition: Build machines that learn through examples (data) and generalize to unseen data\n",
    "\n",
    "\n",
    "Examples we are all using in a daily basis:\n",
    "\n",
    "      - Car plate detection systems\n",
    "      - spam email classifier  \n",
    "      - voice recognition in smartphones\n",
    "      - face recognition @ facebook \n",
    "      - amazon recomendations  \n",
    "      \n",
    "\n",
    "Aim of this series is to build the foundations and principles to be able to implement some of this systems from scratch. \n",
    "\n",
    "\n",
    "### Introduction and definitions \n",
    "\n",
    "\n",
    "\n",
    "#### Supervised Learning\n",
    "   \n",
    "    Here, the data comes with (a fixed number of) labels  \n",
    "    \n",
    "      \n",
    "      - a dataset of emails and for every email a flag if it is spam or not spam \n",
    "      - photos of animals, where for each photo we have a label if it is a cat or a dog (assume for a moment there is only one animal per photo) \n",
    "      - fraud detection: a dataset with valid and fraudulent transation examples\n",
    "      \n",
    "#### Unsupervised Learning\n",
    "    \n",
    "     In the unsupervised learning case, data comes without labels \n",
    "     \n",
    "     - a collection of documents\n",
    "     - a collection of photographs\n",
    "     - timeseries data\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "#### Regression (Παλλινδρόμηση)\n",
    "\n",
    "      In regression, the outcome we are trying to predict is or can be thought as real number (for example house prices, demand etc)    \n",
    "\n",
    "#### Classification (Ταξινόμηση)\n",
    "    \n",
    "    In classification the target variable is one of many categories. For example (cat, dog, bird), (spam, non-spam), (fraud, non-fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification \n",
    "\n",
    "The repeating pattern in supervised learing is that data comes with labels and we wish to build a system to be able to predict the label given a new data example. For example, if we are building a pet detection system, we would like the system to answer that this is a photo of a cat with very high accuracy, eg predict the class of of the new image to be cat and not dog or bird.\n",
    "\n",
    "\n",
    "<b><span style=\"color:red\">WARNING: MATHS AHEAD</span></b>\n",
    "\n",
    "Without being too formal, we would like to learn from the data a function $f(x) \\to D $, where $x \\in X$ is the data and D the set of the labels to be predicted.\n",
    "\n",
    "This function must have the property to be able to produce correct results in new, unseen data. That is, if we take a photo of a random cat somewhere in the world and we feed this cat in to our system, the system should be able to respond that this is a cat although it has never seen this cat before. We call this fuction property \"Gereralisation\" and is the most important aspect of machine learning systems: to be able to perform well in unseen data.\n",
    "\n",
    "\n",
    "Given the above, we need the following ingredients to build a machine learning system\n",
    "- The function we are going to be using to model our data (usually called hypothesis) \n",
    "- A way to measure how \"wrong\" is this function and a configuration of its parameters, given our data\n",
    "- A way to train this function, eg to modify the parameters in such a way that the error is minimised \n",
    "- A way to test this function to new, unseen data and make a claim of how well we expect this function to behave in unseen data. \n",
    "\n",
    "Similarly, for the regression part, instead of trying to predict a label we now try to predict a real value number. \n",
    "\n",
    "Again we need a hypothesis, a loss function, a way to tune the hypothesis and a way to see how well we are generalizing to unseen data.\n",
    "\n",
    "\n",
    "Let's see that in practice. \n",
    "\n",
    "\n",
    "#### Linear Regression\n",
    "\n",
    "One of  the simplest parametric models in statistics and machine learning is Linear Regression. \n",
    "\n",
    "Linear Regression tries to find a best straight line to fit the data. \n",
    "\n",
    "\n",
    "##### Linear Regression Example\n",
    "\n",
    "![alt text](./images/lr.png \"Linear Regression Example\")\n",
    "\n",
    "\n",
    "\n",
    "We are given a data set D of values  $\\{ (x_i,y_i) \\}$ and our hypothesis is that there is a straight line \n",
    "$y = h(x) = w_0 + w_1 * x$ that fits the data. \n",
    "\n",
    "We are now asked to find the \"best\" weights w that fit our data.\n",
    "\n",
    "A typicall way to define \"best\" is to try to minimize the square difference between our targets y and what the model predicts, $\\hat{y} = f(x)$,  eg minimize the total loss \n",
    "\n",
    "$$ L = \\sum_i{  ( y_i - \\hat{y_i})^2 } = \\sum_i{  ( y_i - \\ w_0 + w_1*x_i )^2 }$$ \n",
    "\n",
    "There a few ways to do that, either look for a closed form analytic expression or use an optimisation algorithm such as gradient descent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generallization, model performance \n",
    "\n",
    "\n",
    "When we are solving a supervised learning problem, we are given data and labels and we want to build a predictive model which will be good enough to generalize to unseen data.\n",
    "\n",
    "\n",
    "\n",
    "### Train/Validation/Test\n",
    "A common way to proceed is to split the data in 3 parts, assuming we have enough data. Sometimes this is a reasonable assumption, some times it is not.\n",
    "\n",
    "\n",
    "We split the data in train, validation and test parts. (80/10/10 typically or something similar)\n",
    "\n",
    "We then train the model in the 80% of the data and we validate/optimise the model in the validate data. When we are happy, then ** and only then ** we are testing the model's performance on the test data. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Cross Validation\n",
    "Another strategy used in practice is Cross Validation.\n",
    "\n",
    "\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "- Shuffle the dataset randomly.\n",
    "- Split the dataset into k groups\n",
    "- For each unique group:\n",
    "       - Take the group as a hold out or test data set\n",
    "        - Take the remaining groups as a training data set\n",
    "        - Fit a model on the training set and evaluate it on the test set\n",
    "        - Retain the evaluation score and discard the model\n",
    "- Summarize the skill of the model using the sample of model evaluation scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimisation \n",
    "\n",
    "\n",
    "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\n",
    "\n",
    "The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data.[1] The objective function takes a tuple of hyperparameters and returns the associated loss.[1] Cross-validation is often used to estimate this generalization performance.[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
